{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "testing NLP.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fraYckXz24sw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "outputId": "301f1970-c2e1-4f8c-dd37-76bd62e879f5"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now\n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKKVf0jKSGRT",
        "colab_type": "code",
        "outputId": "22bd77c0-8e53-447d-d378-6933dded8da5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.datasets import imdb"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cfalPIOSJkT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7c6f20a5-1a5a-4c16-e30d-5ef57bf9ad2a"
      },
      "source": [
        "(X_train, y_train), (X_valid, y_valid) = imdb.load_data(num_words=5000, skip_top=50) "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlwXTpo-WPxN",
        "colab_type": "code",
        "outputId": "10faabeb-68a1-4882-e0fb-af1f9d29a004",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "X_train[1]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2,\n",
              " 194,\n",
              " 1153,\n",
              " 194,\n",
              " 2,\n",
              " 78,\n",
              " 228,\n",
              " 2,\n",
              " 2,\n",
              " 1463,\n",
              " 4369,\n",
              " 2,\n",
              " 134,\n",
              " 2,\n",
              " 2,\n",
              " 715,\n",
              " 2,\n",
              " 118,\n",
              " 1634,\n",
              " 2,\n",
              " 394,\n",
              " 2,\n",
              " 2,\n",
              " 119,\n",
              " 954,\n",
              " 189,\n",
              " 102,\n",
              " 2,\n",
              " 207,\n",
              " 110,\n",
              " 3103,\n",
              " 2,\n",
              " 2,\n",
              " 69,\n",
              " 188,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 249,\n",
              " 126,\n",
              " 93,\n",
              " 2,\n",
              " 114,\n",
              " 2,\n",
              " 2300,\n",
              " 1523,\n",
              " 2,\n",
              " 647,\n",
              " 2,\n",
              " 116,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 229,\n",
              " 2,\n",
              " 340,\n",
              " 1322,\n",
              " 2,\n",
              " 118,\n",
              " 2,\n",
              " 2,\n",
              " 130,\n",
              " 4901,\n",
              " 2,\n",
              " 2,\n",
              " 1002,\n",
              " 2,\n",
              " 89,\n",
              " 2,\n",
              " 952,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 455,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 1543,\n",
              " 1905,\n",
              " 398,\n",
              " 2,\n",
              " 1649,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 163,\n",
              " 2,\n",
              " 3215,\n",
              " 2,\n",
              " 2,\n",
              " 1153,\n",
              " 2,\n",
              " 194,\n",
              " 775,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 349,\n",
              " 2637,\n",
              " 148,\n",
              " 605,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 123,\n",
              " 125,\n",
              " 68,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 349,\n",
              " 165,\n",
              " 4362,\n",
              " 98,\n",
              " 2,\n",
              " 2,\n",
              " 228,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 1157,\n",
              " 2,\n",
              " 299,\n",
              " 120,\n",
              " 2,\n",
              " 120,\n",
              " 174,\n",
              " 2,\n",
              " 220,\n",
              " 175,\n",
              " 136,\n",
              " 50,\n",
              " 2,\n",
              " 4373,\n",
              " 228,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 656,\n",
              " 245,\n",
              " 2350,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 131,\n",
              " 152,\n",
              " 491,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 1212,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 371,\n",
              " 78,\n",
              " 2,\n",
              " 625,\n",
              " 64,\n",
              " 1382,\n",
              " 2,\n",
              " 2,\n",
              " 168,\n",
              " 145,\n",
              " 2,\n",
              " 2,\n",
              " 1690,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 1355,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 52,\n",
              " 154,\n",
              " 462,\n",
              " 2,\n",
              " 89,\n",
              " 78,\n",
              " 285,\n",
              " 2,\n",
              " 145,\n",
              " 95]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICNofsoHS1n7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c2ee44d5-2937-447e-9b4d-716fa4293af8"
      },
      "source": [
        "word_index = imdb.get_word_index()\n",
        "word_index = {k:v+3 for k,v in word_index.items()}\n",
        "word_index['PAD'] = 0\n",
        "word_index['Start'] = 1\n",
        "word_index['UNK'] = 2\n",
        "word_index['Start']\n",
        "\n",
        "index_word = {v:k for k,v in word_index.items()}"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtNjC776TIpf",
        "colab_type": "code",
        "outputId": "5d7d5c5c-cc90-4ba0-bcb0-99ae2ba1a523",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "' '.join(index_word[i] for i in X_train[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"UNK big hair big UNK bad music UNK UNK giant safety UNK these UNK UNK words UNK best describe UNK terrible UNK UNK love cheesy horror movies UNK i've seen hundreds UNK UNK had got UNK UNK UNK UNK UNK worst ever made UNK plot UNK paper thin UNK ridiculous UNK acting UNK UNK UNK UNK script UNK completely laughable UNK best UNK UNK end showdown UNK UNK cop UNK how UNK worked UNK UNK UNK killer UNK UNK UNK UNK damn terribly written UNK clothes UNK UNK UNK funny UNK equal UNK UNK hair UNK big lots UNK UNK UNK men wear those cut UNK UNK UNK show off their UNK UNK UNK men actually wore them UNK UNK music UNK UNK UNK trash UNK plays over UNK over again UNK almost every scene there UNK trashy music UNK UNK UNK taking away bodies UNK UNK UNK still doesn't close UNK UNK UNK UNK aside UNK UNK UNK truly bad UNK whose only charm UNK UNK look back UNK UNK disaster UNK UNK UNK 80's UNK UNK UNK good old laugh UNK how bad everything UNK back then\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kn1nJ_EJUD7i",
        "colab_type": "code",
        "outputId": "c567a9f5-4a67-43b1-807a-471a7d8031fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "all_train, all_valid = imdb.load_data()\n",
        "all_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
              "        list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 10156, 4, 1153, 9, 194, 775, 7, 8255, 11596, 349, 2637, 148, 605, 15358, 8003, 15, 123, 125, 68, 23141, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 36893, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 25249, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 46151, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
              "        list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 44076, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 51428, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
              "        ...,\n",
              "        list([1, 11, 6, 230, 245, 6401, 9, 6, 1225, 446, 86527, 45, 2174, 84, 8322, 4007, 21, 4, 912, 84, 14532, 325, 725, 134, 15271, 1715, 84, 5, 36, 28, 57, 1099, 21, 8, 140, 8, 703, 5, 11656, 84, 56, 18, 1644, 14, 9, 31, 7, 4, 9406, 1209, 2295, 26094, 1008, 18, 6, 20, 207, 110, 563, 12, 8, 2901, 17793, 8, 97, 6, 20, 53, 4767, 74, 4, 460, 364, 1273, 29, 270, 11, 960, 108, 45, 40, 29, 2961, 395, 11, 6, 4065, 500, 7, 14492, 89, 364, 70, 29, 140, 4, 64, 4780, 11, 4, 2678, 26, 178, 4, 529, 443, 17793, 5, 27, 710, 117, 74936, 8123, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 1242, 1209, 10, 10, 288, 2260, 1702, 34, 2901, 17793, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2766, 234, 1119, 1574, 7, 496, 4, 139, 929, 2901, 17793, 7750, 5, 4241, 18, 4, 8497, 13164, 250, 11, 1818, 7561, 4, 4217, 5408, 747, 1115, 372, 1890, 1006, 541, 9303, 7, 4, 59, 11027, 4, 3586, 22459]),\n",
              "        list([1, 1446, 7079, 69, 72, 3305, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 4120, 2959, 45, 58, 1466, 13, 197, 12, 16, 43, 23, 21469, 5, 62, 30, 145, 402, 11, 4131, 51, 575, 32, 61, 369, 71, 66, 770, 12, 1054, 75, 100, 2198, 8, 4, 105, 37, 69, 147, 712, 75, 3543, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 1814, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 40691, 40, 319, 5872, 112, 6700, 11, 4803, 121, 25, 70, 3468, 4, 719, 3798, 13, 18, 31, 62, 40, 8, 7200, 4, 29455, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 11418, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 21213, 12, 38, 84, 80, 124, 12, 9, 23]),\n",
              "        list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 12815, 270, 14437, 5, 16923, 12255, 732, 2098, 101, 405, 39, 14, 1034, 4, 1310, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 4039, 9245, 9, 24, 6, 78, 1099, 17, 2345, 16553, 21, 27, 9685, 6139, 5, 29043, 1603, 92, 1183, 4, 1310, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 6789, 85010, 9, 6, 66, 78, 1099, 4, 631, 1191, 5, 2642, 272, 191, 1070, 6, 7585, 8, 2197, 70907, 10755, 544, 5, 383, 1271, 848, 1468, 12183, 497, 16876, 8, 1597, 8778, 19280, 21, 60, 27, 239, 9, 43, 8368, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 1791, 72, 7, 51, 6, 1739, 22, 4, 204, 131, 9])],\n",
              "       dtype=object), array([1, 0, 0, ..., 0, 1, 0]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQStygxdUMB1",
        "colab_type": "code",
        "outputId": "a4d2137c-d2a6-474b-e5b6-002cc96ef53f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "' '.join(index_word[i] for i in all_train[0][1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Start big hair big boobs bad music and a giant safety pin these are the words to best describe this terrible movie i love cheesy horror movies and i've seen hundreds but this had got to be on of the worst ever made the plot is paper thin and ridiculous the acting is an abomination the script is completely laughable the best is the end showdown with the cop and how he worked out who the killer is it's just so damn terribly written the clothes are sickening and funny in equal measures the hair is big lots of boobs bounce men wear those cut tee shirts that show off their stomachs sickening that men actually wore them and the music is just synthesiser trash that plays over and over again in almost every scene there is trashy music boobs and paramedics taking away bodies and the gym still doesn't close for bereavement all joking aside this is a truly bad film whose only charm is to look back on the disaster that was the 80's and have a good old laugh at how bad everything was back then\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pCsSFp9UOd3",
        "colab_type": "code",
        "outputId": "f9eb5a4f-8bbe-49d8-b6a2-688af82af354",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "' '.join(index_word[i] for i in X_train[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"UNK big hair big UNK bad music UNK UNK giant safety UNK these UNK UNK words UNK best describe UNK terrible UNK UNK love cheesy horror movies UNK i've seen hundreds UNK UNK had got UNK UNK UNK UNK UNK worst ever made UNK plot UNK paper thin UNK ridiculous UNK acting UNK UNK UNK UNK script UNK completely laughable UNK best UNK UNK end showdown UNK UNK cop UNK how UNK worked UNK UNK UNK killer UNK UNK UNK UNK damn terribly written UNK clothes UNK UNK UNK funny UNK equal UNK UNK hair UNK big lots UNK UNK UNK men wear those cut UNK UNK UNK show off their UNK UNK UNK men actually wore them UNK UNK music UNK UNK UNK trash UNK plays over UNK over again UNK almost every scene there UNK trashy music UNK UNK UNK taking away bodies UNK UNK UNK still doesn't close UNK UNK UNK UNK aside UNK UNK UNK truly bad UNK whose only charm UNK UNK look back UNK UNK disaster UNK UNK UNK 80's UNK UNK UNK good old laugh UNK how bad everything UNK back then\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upEeWRPeVgp6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "X_train = pad_sequences(X_train, maxlen=400)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjpYx-i_WG_Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_valid = pad_sequences(X_valid, maxlen=400)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mgfi4l0oWKHJ",
        "colab_type": "code",
        "outputId": "11b5f169-5625-4c40-abd5-c61db957b1cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(X_train[1])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ny-MaHM9WMBR",
        "colab_type": "code",
        "outputId": "27eaa38f-bc31-4f07-ad21-f895e1e7dae2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "model = keras.Sequential([\n",
        "                          keras.layers.Embedding(5000, 64, input_length=100),\n",
        "                          keras.layers.Flatten(),\n",
        "                          keras.layers.Dense(64, activation='relu'),\n",
        "                          keras.layers.Dropout(0.5),\n",
        "                          keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgMGim6rXacr",
        "colab_type": "code",
        "outputId": "3e3f37c3-8666-47ca-fe71-fa6aff0be95c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JG-FDH3XlQw",
        "colab_type": "code",
        "outputId": "31c43bc0-7b21-43ce-885b-fa829a26150f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "model.fit(X_train, y_train, epochs=4,batch_size=128, validation_data=(X_valid, y_valid))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/4\n",
            "25000/25000 [==============================] - 4s 179us/sample - loss: 0.5365 - acc: 0.7109 - val_loss: 0.3521 - val_acc: 0.8462\n",
            "Epoch 2/4\n",
            "25000/25000 [==============================] - 4s 174us/sample - loss: 0.2640 - acc: 0.8967 - val_loss: 0.3527 - val_acc: 0.8438\n",
            "Epoch 3/4\n",
            "25000/25000 [==============================] - 4s 171us/sample - loss: 0.0970 - acc: 0.9731 - val_loss: 0.4454 - val_acc: 0.8307\n",
            "Epoch 4/4\n",
            "25000/25000 [==============================] - 4s 167us/sample - loss: 0.0219 - acc: 0.9974 - val_loss: 0.5400 - val_acc: 0.8321\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa9f2c1a080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7D2R59FZX0RW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_hat = model.predict_proba(X_valid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1SRsyGQX8ON",
        "colab_type": "code",
        "outputId": "99ef7367-8a07-457b-b47d-849825729229",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.hist(y_hat);"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSJIwDCRJwP8CtmCln9+KeK4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rxXaVNYY1G8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_float = []\n",
        "for i in y_hat:\n",
        "  y_float.append(i[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrWJnLEGZM_r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(list(zip(y_float, y_valid)), columns = ['y_hat', 'y'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sgN2sCkZb_N",
        "colab_type": "code",
        "outputId": "30cb121b-0d29-4c12-e7d2-dea2bd48c724",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "df[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y_hat</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.044160</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.999443</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.996632</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.032796</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.999697</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.970078</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.935797</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.000007</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.975446</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.994153</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      y_hat  y\n",
              "0  0.044160  0\n",
              "1  0.999443  1\n",
              "2  0.996632  1\n",
              "3  0.032796  0\n",
              "4  0.999697  1\n",
              "5  0.970078  1\n",
              "6  0.935797  1\n",
              "7  0.000007  0\n",
              "8  0.975446  0\n",
              "9  0.994153  1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DbeeQWiZe0N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = keras.Sequential([\n",
        "                      keras.layers.Embedding(5000, 64, input_length=100),\n",
        "                      keras.layers.SpatialDropout1D(0.2),\n",
        "                      keras.layers.Conv1D(256, 3, activation='relu'),\n",
        "                      keras.layers.GlobalMaxPooling1D(),\n",
        "                      keras.layers.Dense(64, activation='relu'),\n",
        "                      keras.layers.Dropout(0.2),\n",
        "                      keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mgkdaGUaTMS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zfE3NAdb7PB",
        "colab_type": "code",
        "outputId": "68d9740b-c9b0-4b14-b186-b9ece68c7c54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "model.fit(X_train, y_train, epochs=4,batch_size=128, validation_data=(X_valid, y_valid))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/4\n",
            "25000/25000 [==============================] - 26s 1ms/sample - loss: 0.1348 - acc: 0.9540 - val_loss: 0.4427 - val_acc: 0.8331\n",
            "Epoch 2/4\n",
            "25000/25000 [==============================] - 26s 1ms/sample - loss: 0.0874 - acc: 0.9722 - val_loss: 0.5189 - val_acc: 0.8275\n",
            "Epoch 3/4\n",
            "25000/25000 [==============================] - 26s 1ms/sample - loss: 0.0534 - acc: 0.9837 - val_loss: 0.5968 - val_acc: 0.8295\n",
            "Epoch 4/4\n",
            "25000/25000 [==============================] - 26s 1ms/sample - loss: 0.0376 - acc: 0.9886 - val_loss: 0.6490 - val_acc: 0.8274\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa9eeb2bac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-kLFr18b9XQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = [word_index[i] for i in 'this movie is bad'.split()] \n",
        "y = [word_index[i]  for i in 'the movie is terrible and i do not recommend it watching it'.split()] \n",
        "X = [x,y]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCyA33tddZFI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "X = pad_sequences(np.array(X), maxlen=400)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CL41EhYplPRU",
        "colab_type": "code",
        "outputId": "0db95b91-c437-4f95-aaa2-b51499d058f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "model.predict(X)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.29738444],\n",
              "       [0.01679195]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqeQGkaRdd7a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "outputId": "33bf8f11-cc8f-48e4-9cd2-616f2a754799"
      },
      "source": [
        "from tensorflow import keras \n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now\n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fygPVpsbdmMT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "keras.Sequential?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BKw4Ii5HX73",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "1d15dc98-4988-4215-da77-9215b3f2cac1"
      },
      "source": [
        "input_layer = keras.layers.Input(shape=(400,),dtype= 'int16', name='input_layer')\n",
        "embed_layer = keras.layers.Embedding(5000, 64, name='embeding_layer')(input_layer)\n",
        "embed_dropout = keras.layers.SpatialDropout1D(0.2)(embed_layer)\n",
        "conv_1 = keras.layers.Conv1D(256, 3, activation='relu', name='conv_1')(embed_dropout)\n",
        "max1 = keras.layers.GlobalMaxPooling1D()(conv_1)\n",
        "\n",
        "conv_2 = keras.layers.Conv1D(256, 3, activation='relu', name='conv_2')(embed_dropout)\n",
        "max2 = keras.layers.GlobalMaxPooling1D()(conv_2)\n",
        "\n",
        "conv_3 = keras.layers.Conv1D(256, 3, activation='relu', name='conv_3')(embed_dropout)\n",
        "max3 = keras.layers.GlobalMaxPooling1D()(conv_3)\n",
        "concat = keras.layers.concatenate([max1, max2, max3])\n",
        "dense_1 = keras.layers.Dense(256, activation='relu', name='dense1')(concat)\n",
        "dense1_dropout = keras.layers.Dropout(0.2)(dense_1)\n",
        "\n",
        "dense_2 = keras.layers.Dense(256, activation='relu', name='dense2')(dense1_dropout)\n",
        "dense2_dropout = keras.layers.Dropout(0.2)(dense_2)\n",
        "\n",
        "predictions = keras.layers.Dense(1, activation='sigmoid', name='last_layer')(dense2_dropout)\n",
        "model = keras.models.Model(input_layer, predictions)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9dMl798SLE5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "fd55c216-400d-4934-8ecb-3cee381ce652"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-faec0MBS_b1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "1ba943c6-df2d-4d0f-d7a9-95c14fbe46ad"
      },
      "source": [
        "model.fit(X_train, y_train, epochs=4,batch_size=128, validation_data=(X_valid, y_valid))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/4\n",
            "25000/25000 [==============================] - 12s 486us/sample - loss: 0.4795 - acc: 0.7457 - val_loss: 0.3117 - val_acc: 0.8662\n",
            "Epoch 2/4\n",
            "25000/25000 [==============================] - 6s 224us/sample - loss: 0.2662 - acc: 0.8929 - val_loss: 0.2873 - val_acc: 0.8796\n",
            "Epoch 3/4\n",
            "25000/25000 [==============================] - 6s 222us/sample - loss: 0.1822 - acc: 0.9301 - val_loss: 0.3033 - val_acc: 0.8808\n",
            "Epoch 4/4\n",
            "25000/25000 [==============================] - 6s 221us/sample - loss: 0.1219 - acc: 0.9562 - val_loss: 0.3326 - val_acc: 0.8763\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa2fc9c0eb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxrSOCuATBB7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}